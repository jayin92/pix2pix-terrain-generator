#pragma kernel RaytracingAreaShadowPrepass
#pragma kernel RaytracingAreaShadowNewSample
#pragma kernel RaytracingDirectionalShadowSample
#pragma kernel ClearShadowTexture
#pragma kernel OutputShadowTexture

// Given that the algorithm requires BSDF evaluation, we need to define this macro
#define HAS_LIGHTLOOP

// Given that the algorithm requires BSDF evaluation, we need to define this macro
#define SKIP_RASTERIZED_SHADOWS

// Given that this pass does not use the shadow algorithm multi-compile, we need to define SHADOW_LOW to quite the shadow algorithm error
#define SHADOW_LOW

// Include and define the shader pass
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/ShaderPass/ShaderPass.cs.hlsl"
#define SHADERPASS SHADERPASS_RAYTRACING

// HDRP generic includes
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Color.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/ShaderLibrary/ShaderVariables.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Lighting/Lighting.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Material/Material.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Lighting/LightLoop/LightLoopDef.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Material/Lit/Lit.hlsl"

// Raytracing includes
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/Raytracing/Shaders/ShaderVariablesRaytracing.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/Raytracing/Shaders/RaytracingSampling.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/Raytracing/Shaders/Shadows/SphericalQuad.hlsl"
#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/Raytracing/Shaders/Shadows/RaytracingMIS.hlsl"

#pragma only_renderers d3d11

// Tile size of this compute
#define RAYTRACING_SHADOW_TILE_SIZE 8

// The target acceleration structure that we will evaluate the reflexion in
TEXTURE2D_X(_DepthTexture);

// The target area light to raytrace
uint                        _RaytracingTargetAreaLight;

// Output buffers of the shadows raytrace shader
RW_TEXTURE2D_X(float2, _AnalyticProbBuffer);
RW_TEXTURE2D_X(float2, _RaytracedAreaShadowSample);
RW_TEXTURE2D_X(float2, _RaytracedAreaShadowIntegration);
RW_TEXTURE2D_X(float4, _RaytracingDirectionBuffer);
RW_TEXTURE2D_X(float, _RaytracingDistanceBuffer);
RWTexture2DArray<float>     _ScreenSpaceShadowsTextureRW;

// Prepass that evaluates the data required for the ray tracing
[numthreads(RAYTRACING_SHADOW_TILE_SIZE, RAYTRACING_SHADOW_TILE_SIZE, 1)]
void RaytracingAreaShadowPrepass(uint2 groupThreadId : SV_GroupThreadID, uint2 groupId : SV_GroupID)
{
    // Compute the pixel position to process
    uint2 currentCoord = groupId * RAYTRACING_SHADOW_TILE_SIZE + groupThreadId;

    // The value -1.0 is used to identify an invalid pixel
    _AnalyticProbBuffer[COORD_TEXTURE2D_X(currentCoord)] = float2(-1.0, -1.0);
    _RaytracedAreaShadowIntegration[COORD_TEXTURE2D_X(currentCoord)] = float2(0.0, 0.0);

    // Values that need to be defined per sample
    _RaytracedAreaShadowSample[COORD_TEXTURE2D_X(currentCoord)] = float2(0.0, 0.0);
    _RaytracingDirectionBuffer[COORD_TEXTURE2D_X(currentCoord)] = float4(0.0, 0.0, 0.0, 0.0);
    _RaytracingDistanceBuffer[COORD_TEXTURE2D_X(currentCoord)] = 0.0;

    // Read the depth value
    float depthValue = LOAD_TEXTURE2D_X(_DepthTexture, currentCoord).x;
    if (depthValue == UNITY_RAW_FAR_CLIP_VALUE)
        return;

    // Compute the position input structure
    PositionInputs posInput = GetPositionInput(currentCoord, _ScreenSize.zw, depthValue, UNITY_MATRIX_I_VP, GetWorldToViewMatrix(), 0);

    // Let's now decode the BSDF data from the  gbuffer
    BSDFData bsdfData;
    ZERO_INITIALIZE(BSDFData, bsdfData);
    BuiltinData builtinData;
    ZERO_INITIALIZE(BuiltinData, builtinData);
    uint  featureFlags = MATERIALFEATUREFLAGS_LIT_STANDARD;
    DecodeFromGBuffer(posInput.positionSS, featureFlags, bsdfData, builtinData);

    // Convert this to a world space position
    float3 positionWS = GetAbsolutePositionWS(posInput.positionWS);

    // Compute the view vector on the surface
    float3 viewWS = normalize(_WorldSpaceCameraPos - positionWS);

    // Fetch the data of the area light
    LightData lightData = _LightDatas[_RaytracingTargetAreaLight];

    // Structure that holds all the input data for the MIS
    MISSamplingInput misInput;
    ZERO_INITIALIZE(MISSamplingInput, misInput);
    misInput.roughness = PerceptualRoughnessToRoughness(bsdfData.perceptualRoughness);
    misInput.viewWS = viewWS;
    misInput.positionWS = positionWS;
    misInput.rectDimension = lightData.size.xy;
    misInput.rectWSPos = GetAbsolutePositionWS(lightData.positionRWS);

    // Setup and check the spherical rectangle
    SphQuad squad;
    InitSphericalQuad(lightData, positionWS, squad);

    // Compute the local frame that matches the normal
    misInput.localToWorld = GetLocalFrame(bsdfData.normalWS);

    // Beyond a certain value of smoothness, we clamp due to the invalidity of the ratio BRDF / MIS.
    // TODO: investigate this and find a way to by pass it
    bsdfData.perceptualRoughness = ClampPerceptualRoughnessForRaytracing(bsdfData.perceptualRoughness);
    bsdfData.roughnessT = ClampRoughnessForRaytracing(bsdfData.roughnessT);
    bsdfData.roughnessB = ClampRoughnessForRaytracing(bsdfData.roughnessB);

    // Compute the prelight data
    PreLightData preLightData = GetPreLightData(viewWS, posInput, bsdfData);

    // Compute the direct lighting of the light (used for MIS)
    LightLoopContext context;
    // Given that the approximation used for LTC is completely different from what we would get from a real integration, we only rely on the not textured intensity.
    // To acheive that, we set cookie index to -1 so that the evaluatebsdf_rect function to not use any cookie. We also keep track of that cookie value to restore it after the evaluation.
    int cookieIndex = lightData.cookieIndex;
    lightData.cookieIndex = -1;
    DirectLighting lighting = EvaluateBSDF_Rect(context, viewWS, posInput, preLightData, lightData, bsdfData, builtinData);
    lighting.diffuse = lighting.diffuse * bsdfData.diffuseColor;
    lightData.cookieIndex = cookieIndex;

    // Compute the non-occluded analytic luminance value
    float U = Luminance(lighting.diffuse + lighting.specular);

    // NOTE: Due to a VGPR optimisation in we need to restore the previous value (position, dimmer, and other thing are overriden)
    lightData = _LightDatas[_RaytracingTargetAreaLight];

    // Here we need to evaluate the diffuseProbablity and the unshadowed lighting
    if(!EvaluateMISProbabilties(lighting, bsdfData.perceptualRoughness, misInput.brdfProb))
    {
        // We want this to be flagged as a proper shadow, and not a 0/0 case
        _RaytracedAreaShadowIntegration[COORD_TEXTURE2D_X(currentCoord)] = float2(0.0, 0.0);
        _AnalyticProbBuffer[COORD_TEXTURE2D_X(currentCoord)] = float2(-1.0, -1.0);
        return;
    }

    // Get the scramblingValue of this pixel
    uint2 scramblingValue = ScramblingValue(currentCoord.x, currentCoord.y);

    // Structure that holds all the output data from the MIS
    MISSamplingOuput misOutput;
    ZERO_INITIALIZE(MISSamplingOuput, misOutput);

    // Compute the current sample index
    int globalSampleIndex = _RaytracingFrameIndex * _RaytracingNumSamples;

    // Generate the new sample (follwing values of the sequence)
    float2 noiseValue = float2(0.0, 0.0);
    misInput.noiseValue.x = GetRaytracingNoiseSample(globalSampleIndex, 0, scramblingValue.x);
    misInput.noiseValue.y = GetRaytracingNoiseSample(globalSampleIndex, 1, scramblingValue.y);
    // Pick the sampling technique
    EvaluateMISTechnique(misInput);

    // Generate the right MIS Sample
    bool validity = GenerateMISSample(misInput, squad, viewWS,  misOutput);

    // If we could not sample , or the sample is not in the hemisphere or the sample is on the backface of the light
    if (!validity || dot(misOutput.dir, bsdfData.normalWS) <= 0.0 || dot(misOutput.dir, lightData.forward) >= 0.0)
    {
        _RaytracedAreaShadowSample[COORD_TEXTURE2D_X(currentCoord)] = float2(0.0, 0.0);
        _AnalyticProbBuffer[COORD_TEXTURE2D_X(currentCoord)] = float2(U, misInput.brdfProb);
        return;
    }

    // Evaluate the lighting
    CBSDF cbsdf = EvaluateBSDF(viewWS, misOutput.dir, preLightData, bsdfData);
    float3 diffuseLighting = cbsdf.diffR;
    float3 specularLighting = cbsdf.specR;

    // Combine the light color with the light cookie color (if any)
    float3 lightColor = lightData.color;
    if (lightData.cookieIndex >= 0)
    {
        lightColor *= SAMPLE_TEXTURE2D_ARRAY_LOD(_AreaCookieTextures, s_trilinear_clamp_sampler, misOutput.sampleUV, lightData.cookieIndex, bsdfData.perceptualRoughness *  _CookieSizePOT).xyz;
    }

    diffuseLighting *= bsdfData.diffuseColor * lightData.diffuseDimmer * lightColor;
    specularLighting *= lightData.specularDimmer * lightColor;

    // Compute the MIS weight
    float misPDF = lerp(misOutput.lightPDF, misOutput.brdfPDF, misInput.brdfProb);
    float3 radiance = misPDF > 0.0 ? (diffuseLighting + specularLighting) / misPDF : 0.0;

    // Accumulate
    float3 Un = radiance;

    // Compute luminance of Un
    float UnL = Luminance(Un) / _RaytracingNumSamples;

    // To avoid huge values on low PDFs (leading to potential precision issues),
    // we clip them proportionally to the unoccluded analytic value
    const float unoccludedThreshold = 10.0 * U;
    if (UnL > unoccludedThreshold)
    {
        UnL = unoccludedThreshold;
    }

    // Pass on the values to the output buffer (Sn, Un) and (U)
    _RaytracedAreaShadowSample[COORD_TEXTURE2D_X(currentCoord)] = float2(UnL, UnL);
    _AnalyticProbBuffer[COORD_TEXTURE2D_X(currentCoord)] = float2(U, misInput.brdfProb);

    // Let's shift the origin and destination positions by a bias
    float3 rayOrigin = positionWS;
    float3 rayDestination = misOutput.pos;
    float rayDistance = length(rayDestination-rayOrigin);
    float3 rayDirection = (rayDestination - rayOrigin) / rayDistance;

    _RaytracingDirectionBuffer[COORD_TEXTURE2D_X(currentCoord)] = float4(rayDirection, 1.0f);
    _RaytracingDistanceBuffer[COORD_TEXTURE2D_X(currentCoord)] = rayDistance;
}

// Prepass that evaluates the data required for the ray tracing
[numthreads(RAYTRACING_SHADOW_TILE_SIZE, RAYTRACING_SHADOW_TILE_SIZE, 1)]
void RaytracingAreaShadowNewSample(uint2 groupThreadId : SV_GroupThreadID, uint2 groupId : SV_GroupID)
{
    // Compute the pixel position to process
    uint2 currentCoord = groupId * RAYTRACING_SHADOW_TILE_SIZE + groupThreadId;

    // Read the depth value
    float depthValue  = LOAD_TEXTURE2D_X(_DepthTexture, currentCoord).x;
    if (depthValue == UNITY_RAW_FAR_CLIP_VALUE || _AnalyticProbBuffer[COORD_TEXTURE2D_X(currentCoord)].x < 0.0)
    {
        _RaytracedAreaShadowSample[COORD_TEXTURE2D_X(currentCoord)] = float2(0.0, 0.0);
        return;
    }

    // Compute the position input structure
    PositionInputs posInput = GetPositionInput(currentCoord, _ScreenSize.zw, depthValue, UNITY_MATRIX_I_VP, GetWorldToViewMatrix(), 0);

    // Let's now decode the BSDF data from the  gbuffer
    BSDFData bsdfData;
    ZERO_INITIALIZE(BSDFData, bsdfData);
    BuiltinData builtinData;
    ZERO_INITIALIZE(BuiltinData, builtinData);
    // Decode BSDF Data
    uint  featureFlags = MATERIALFEATUREFLAGS_LIT_STANDARD;
    DecodeFromGBuffer(posInput.positionSS, featureFlags, bsdfData, builtinData);

    // Beyond a certain value of smoothness, we clamp due to the invalidity of the ratio BRDF / MIS.
    // TODO: investigate this and find a way to by pass it
    bsdfData.perceptualRoughness = ClampPerceptualRoughnessForRaytracing(bsdfData.perceptualRoughness);
    bsdfData.roughnessT = ClampRoughnessForRaytracing(bsdfData.roughnessT);
    bsdfData.roughnessB = ClampRoughnessForRaytracing(bsdfData.roughnessB);

    // Fetch the data of the area light
    LightData lightData = _LightDatas[_RaytracingTargetAreaLight];

    // Convert this to a world space position
    float3 positionWS = GetAbsolutePositionWS(posInput.positionWS);

    // Compute the view vector on the surface
    float3 viewWS = normalize(_WorldSpaceCameraPos - positionWS);

    // Compute the prelight data
    PreLightData preLightData = GetPreLightData(viewWS, posInput, bsdfData);

    // Our shader only processes luminance
    float U = _AnalyticProbBuffer[COORD_TEXTURE2D_X(currentCoord)].x;

    // Structure that holds all the input data for the MIS
    MISSamplingInput misInput;
    ZERO_INITIALIZE(MISSamplingInput, misInput);
    misInput.roughness = PerceptualRoughnessToRoughness(bsdfData.perceptualRoughness);
    misInput.viewWS = viewWS;
    misInput.positionWS = positionWS;
    misInput.rectDimension = lightData.size.xy;
    misInput.rectWSPos = GetAbsolutePositionWS(lightData.positionRWS);
    misInput.brdfProb = _AnalyticProbBuffer[COORD_TEXTURE2D_X(currentCoord)].y;

    // Setup and check the spherical rectangle
    SphQuad squad;
    InitSphericalQuad(lightData, positionWS, squad);

    // Compute the local frame that matches the normal
    misInput.localToWorld = GetLocalFrame(bsdfData.normalWS);

    // Structure that holds all the output data from the MIS
    MISSamplingOuput misOutput;
    ZERO_INITIALIZE(MISSamplingOuput, misOutput);

    // Get the scramblingValue of this pixel
    uint2 scramblingValue = ScramblingValue(currentCoord.x, currentCoord.y);

    // Compute the current sample index
    int globalSampleIndex = _RaytracingFrameIndex * _RaytracingNumSamples + _RaytracingSampleIndex;

    // Generate the new sample (follwing values of the sequence)
    float2 noiseValue = float2(0.0, 0.0);
    misInput.noiseValue.x = GetRaytracingNoiseSample(globalSampleIndex, 0, scramblingValue.x);
    misInput.noiseValue.y = GetRaytracingNoiseSample(globalSampleIndex, 1, scramblingValue.y);

    // Pick the sampling technique
    EvaluateMISTechnique(misInput);

    // Generate the right MIS Sample
    bool validity = GenerateMISSample(misInput, squad, viewWS,  misOutput);

    // If we could not sample , or the sample is not in the hemisphere or the sample is on the backface of the light
    if (!validity || dot(misOutput.dir, bsdfData.normalWS) <= 0.0 || dot(misOutput.dir, lightData.forward) >= 0.0)
    {
        _RaytracedAreaShadowSample[COORD_TEXTURE2D_X(currentCoord)] = float2(0.0, 0.0);
        return;
    }

    // Evaluate the lighting
    CBSDF cbsdf = EvaluateBSDF(viewWS, misOutput.dir, preLightData, bsdfData);
    float3 diffuseLighting = cbsdf.diffR;
    float3 specularLighting = cbsdf.specR;

    // Combine the light color with the light cookie color (if any)
    float3 lightColor = lightData.color;
    if (lightData.cookieIndex >= 0)
    {
        lightColor *= SAMPLE_TEXTURE2D_ARRAY_LOD(_AreaCookieTextures, s_trilinear_clamp_sampler, misOutput.sampleUV, lightData.cookieIndex, bsdfData.perceptualRoughness *  _CookieSizePOT).xyz;
    }

    diffuseLighting *= bsdfData.diffuseColor * lightData.diffuseDimmer * lightColor;
    specularLighting *= lightData.specularDimmer * lightColor;

    // Compute the MIS weight
    float misPDF = lerp(misOutput.lightPDF, misOutput.brdfPDF, misInput.brdfProb);
    float3 radiance = misPDF > 0.0 ? (diffuseLighting + specularLighting) / misPDF : 0.0;

    // Accumulate
    float3 Un = radiance;

    // Compute luminance of Un
    float UnL = Luminance(Un) / _RaytracingNumSamples;

    // To avoid huge values on low PDFs (leading to potential precision issues),
    // we clip them proportionally to the unoccluded analytic value
    const float unoccludedThreshold = 10.0 * U;
    if (UnL > unoccludedThreshold)
    {
        UnL = unoccludedThreshold;
    }

    // Pass on the values to the output buffer (Sn, Un) and (U)
    _RaytracedAreaShadowSample[COORD_TEXTURE2D_X(currentCoord)] = float2(UnL, UnL);

    // Let's shift the origin and destination positions by a bias
    float3 rayOrigin = positionWS;
    float3 rayDestination = misOutput.pos;
    float rayDistance = length(rayDestination - rayOrigin);
    float3 rayDirection = (rayDestination - rayOrigin) / rayDistance;

    _RaytracingDirectionBuffer[COORD_TEXTURE2D_X(currentCoord)] = float4(rayDirection, 1.0f);
    _RaytracingDistanceBuffer[COORD_TEXTURE2D_X(currentCoord)] = rayDistance;
}

RW_TEXTURE2D_X(float, _RaytracedDirectionalShadowIntegration);

[numthreads(RAYTRACING_SHADOW_TILE_SIZE, RAYTRACING_SHADOW_TILE_SIZE, 1)]
void ClearShadowTexture(uint2 groupThreadId : SV_GroupThreadID, uint2 groupId : SV_GroupID)
{
    // Compute the pixel position to process
    uint2 currentCoord = groupId * RAYTRACING_SHADOW_TILE_SIZE + groupThreadId;
    _RaytracedDirectionalShadowIntegration[COORD_TEXTURE2D_X(currentCoord)] = 0.0;
}

float _DirectionalLightAngle;

// Prepass that evaluates the data required for the ray tracing
[numthreads(RAYTRACING_SHADOW_TILE_SIZE, RAYTRACING_SHADOW_TILE_SIZE, 1)]
void RaytracingDirectionalShadowSample(uint2 groupThreadId : SV_GroupThreadID, uint2 groupId : SV_GroupID)
{
    // Compute the pixel position to process
    uint2 currentCoord = groupId * RAYTRACING_SHADOW_TILE_SIZE + groupThreadId;

    // Read the depth value
    float depthValue = LOAD_TEXTURE2D_X(_DepthTexture, currentCoord).x;
    if (depthValue == UNITY_RAW_FAR_CLIP_VALUE)
        return;

    // Compute the position input structure
    PositionInputs posInput = GetPositionInput(currentCoord, _ScreenSize.zw, depthValue, UNITY_MATRIX_I_VP, GetWorldToViewMatrix(), 0);

    // Decode the world space normal
    NormalData normalData;
    DecodeFromNormalBuffer(currentCoord, normalData);

    // Convert this to a world space position
    float3 positionWS = GetAbsolutePositionWS(posInput.positionWS);

    // Fetch the data of the area light
    DirectionalLightData lightData = _DirectionalLightDatas[_DirectionalShadowIndex];

    // Get the scramblingValue of this pixel
    uint2 scramblingValue = ScramblingValue(currentCoord.x, currentCoord.y);

    // Compute the current sample index
    int globalSampleIndex = _RaytracingFrameIndex * _RaytracingNumSamples + _RaytracingSampleIndex;

    // Generate the new sample (follwing values of the sequence)
    float2 noiseValue = float2(0.0, 0.0);
    noiseValue.x = GetRaytracingNoiseSample(globalSampleIndex, 0, scramblingValue.x);
    noiseValue.y = GetRaytracingNoiseSample(globalSampleIndex, 1, scramblingValue.y);

    // Create the local ortho basis
    float3x3 localToWorld = GetLocalFrame(-lightData.forward);

    float3 localDir = SampleConeUniform(noiseValue.x, noiseValue.y, cos(_DirectionalLightAngle * 3.14 / 180.0));

    float3 wsDir = mul(localDir, localToWorld); 
    // Output the direction to the target uav
    _RaytracingDirectionBuffer[COORD_TEXTURE2D_X(currentCoord)] = float4(wsDir, 1.0f);
}

int _RaytracingShadowSlot;

[numthreads(RAYTRACING_SHADOW_TILE_SIZE, RAYTRACING_SHADOW_TILE_SIZE, 1)]
void OutputShadowTexture(uint2 groupThreadId : SV_GroupThreadID, uint2 groupId : SV_GroupID)
{
    // Compute the pixel position to process
    uint2 currentCoord = groupId * RAYTRACING_SHADOW_TILE_SIZE + groupThreadId;
    _ScreenSpaceShadowsTextureRW[uint3(currentCoord, _RaytracingShadowSlot)] = _RaytracedDirectionalShadowIntegration[COORD_TEXTURE2D_X(currentCoord)].x / (float) _RaytracingNumSamples;
}
